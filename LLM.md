https://www.promptingguide.ai/

# 

# Chain of Thought

Vanilla: Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In NeurIPS, 2022.

thought-observation-action: ReAct: Synergizing Reasoning and Acting in Language Models. In ICLR, 2023.

in plan and out-of-plan: AdaPlanner: Adaptive Planning from Feedback with Language Models. In ArXiv, 2023.

long-term memory by self-reflection: Reflexion: Language Agents with Verbal Reinforcement Learning. In ArXiv, 2023.

majority vote: Complexity-Based Prompting for Multi-Step Reasoning. In ICLR, 2023.

Self-consistency: Self-Consistency Improves Chain of Thought Reasoning in Language Models. In ICLR, 2023.

Tree of thought: Tree of Thoughts: Deliberate Problem Solving with Large Language Models. In ArXiv, 2023.

Graph of thought: Graph of Thoughts: Solving Elaborate Problems with Large Language Model. In ArXiv, 2023.

Algorithm-of-Thought: Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models. In ArXiv, 2023.

Skeleton-of-thought: 



Cumulative Reasoning With Large Language Models. In ArXiv, 2023.



# RL for LLM

## Policy Gradient and Actor-Critic

PPO + nucleus sampling to narrow down possible actions: Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization. In ICLR, 2023.

explore in the vicinity: Semi-Offline Reinforcement Learning for Optimized Text Generation. In ICML, 2023.

## MCTS

Reasoning with Language Model is Planning with World Model. In ArXiv, 2023.

